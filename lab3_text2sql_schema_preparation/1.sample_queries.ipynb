{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6da7eaba-0251-48d7-87cd-d9980104b836",
   "metadata": {},
   "source": [
    "# Lab. 3-1 Schema Preparation-1\n",
    "\n",
    "이 노트북에서는 아래 그림의 1 / 3 과정을 수행합니다. (2는 불필요하여 생략합니다)\n",
    "\n",
    "복잡한 데이터베이스에서 Text2SQL의 가장 어려운 작업은 쿼리 생성에 필요한 스키마를 선별하는 과정, 즉 Schema Linking 입니다.\n",
    "\n",
    "Lab1 / Lab2에서는 Text2SQL을 구현할 수 있는 워크플로 구성에 대해 알아보면서, 스키마 정보는 DB에 직접 테이블 목록과 컬럼 목록을 조회하는 것으로 간소화했습니다.\n",
    "하지만, 현실의 기업 환경에서는 테이블/컬럼 이름이 의미를 축약하고 있어서 LLM이 이를 파악하기 힘들거나, 테이블/컬럼이 너무 많아서 모든 목록을 프롬프트에 담아 전달하는 것이 불가능한 경우가 많습니다.\n",
    "\n",
    "이를 해결하기 위해, 우리 DB에 맞춰 스키마 설명 문서를 정제하고, LLM에 필요한 컨텍스트를 선별하여 제공하는 작업이 필요합니다. 이 노트북에서는 스키마 준비 과정을 시뮬레이션 하기 위해, Chinook DB 설명 문서를 활용하겠습니다. 전체 작업 흐름은 아래와 같이 이어갈 예정입니다.\n",
    "\n",
    "![Intro](../images/text2sql/schema-prep-1.png)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11fa1a10-2fa1-4383-8838-3186b39815e8",
   "metadata": {},
   "source": [
    "## Step 0: OpenSearch 환경 설정"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "801cb0f5-8055-442d-814b-9a0cea8b9020",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install -q opensearch-py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fab1c499-18e0-4fd7-a2d8-e89bb9b4e012",
   "metadata": {},
   "outputs": [],
   "source": [
    "from libs.ssm import parameter_store\n",
    "pm = parameter_store('us-west-2')\n",
    "domain_endpoint = pm.get_params(key=\"chatbot-opensearch_domain_endpoint\", enc=False)\n",
    "opensearch_domain_endpoint = f\"https://{domain_endpoint}\"\n",
    "opensearch_user_id = pm.get_params(key=\"chatbot-opensearch_user_id\", enc=False)\n",
    "opensearch_user_password = pm.get_params(key=\"chatbot-opensearch_user_password\", enc=True)\n",
    "print(opensearch_domain_endpoint)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "385871de-60f4-4930-9ebb-a42f43985283",
   "metadata": {},
   "source": [
    "## Step 1: Schema Description 문서 로드 (위 그림의 `1. Schema Loader`)\n",
    "\n",
    "각 기업에는 Excel / CSV 등으로 스키마 설명 문서가 정의되어 있을 수 있습니다. 이를 Parsing하여 아래의 Schema Description 포맷으로 변경한다고 가정하겠습니다.\n",
    "\n",
    "```\n",
    "{\n",
    "    \"table_name\": {\n",
    "        \"table_desc\": \"Description of the table\",\n",
    "        \"cols\": [\n",
    "            {\n",
    "                \"col\": \"Column Name 1\",\n",
    "                \"col_desc\": \"Description of the column including PK info\"\n",
    "            },\n",
    "            {\n",
    "                \"col\": \"Column Name 2\",\n",
    "                \"col_desc\": \"Description of the column\"\n",
    "            }\n",
    "        ]\n",
    "    }\n",
    "}\n",
    "```\n",
    "\n",
    "초기 설명 문서에는 테이블의 이름과 테이블에 대한 기본 설명, 컬럼 이름과 컬럼에 대한 설명이 포함되어야 합니다. 기업에 잘 정리된 스키마 설명 문서가 없다면, 아주 기본적인 정보만 제공하고 LLM이 이를 증강하여 초기 설명문서 자체를 생성하도록 할 수도 있습니다. 이를 위한 LLM 호출 스크립트는 다음 [링크](https://github.com/kevmyung/db-schema-loader/blob/main/schema_loader.py)를 참고합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "835783d0-5bc3-4bbd-bd16-9cf672270fbf",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "file_path = './chinook_schema.json'\n",
    "\n",
    "with open(file_path, 'r') as file:\n",
    "    schema_description = json.load(file)\n",
    "\n",
    "print(json.dumps(schema_description, indent=4))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f197834e-7ee3-4eb4-9398-d2e0d5789d53",
   "metadata": {},
   "source": [
    "### 이제 Schema Description 문서를 활용해 후속 작업을 이어가겠습니다"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ca849b4-8126-4c9d-bafa-af3e7543fa44",
   "metadata": {},
   "source": [
    "## Step 2: SQL2Text 샘플 쿼리 변환 (위 그림의 `3. Query Translator`)\n",
    "\n",
    "Lab 1 / Lab 2에서 언급했듯이, 좋은 샘플 쿼리를 LLM에게 제공하는 것은 쿼리 작성 뿐만 아니라 Schema Linking에도 도움이 됩니다.\n",
    "\n",
    "그러나, 대부분의 기업 환경에서 자주 사용되는 쿼리를 로그로 관리하고 있는 반면, (기존에 Text2SQL을 사용하지 않았기 때문에) 쿼리에 매칭되는 자연어 질문은 없습니다. \n",
    "\n",
    "Step 2에서는 자주 사용하는 쿼리들을 자연어 질문으로 변환하는 SQL2Text 과정을 진행합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e40dcac-1073-4a4f-9c68-46944c2ce5d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "sql_file = './chinook_sample_queries.sql'\n",
    "\n",
    "with open(sql_file, 'r') as file:\n",
    "    data = file.read()\n",
    "\n",
    "queries = [query.strip() for query in data.split(';') if query.strip()]\n",
    "\n",
    "for i, query in enumerate(queries, start=1):\n",
    "    print(f\"Query {i}:\\n{query}\\n{'-'*80}\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02e58b4f-0b52-4eb1-9d8b-6121cf561aca",
   "metadata": {},
   "source": [
    "쿼리를 해석하기 위해, 각 쿼리에 사용된 테이블/컬럼의 의미를 파악해야 합니다.\n",
    "따라서, 각 쿼리에 사용된 테이블/컬럼 정보를 아래와 같이 추출합니다.\n",
    "```\n",
    "{\n",
    "  \"table\": [\"table1\", \"table2\", ...],\n",
    "  \"column\": [\"col1\", \"col2\", ...]\n",
    "}\n",
    "```\n",
    "다음은 SQL 쿼리에 활용된 스키마 목록을 추출하는 LLM 요청 구문입니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c44c68a7-3c2c-402f-8a57-657d1e160251",
   "metadata": {},
   "outputs": [],
   "source": [
    "SYS_PROMPT_TEMPLATE1 = \"\"\" \n",
    "You are an expert in extracting table names and column names from SQL queries. \n",
    "From the provided SQL query, extract all table names and column names used for SELECT, WHERE, and JOIN clauses, excluding asterisks (\"*\"). \n",
    "Ensure that the response is in a valid JSON format that can be used directly with json.load(). \n",
    "Skip the preamble and only provide the answer in a JSON document:\n",
    "\n",
    "{\n",
    "  \"table\": [\"table1\", \"table2\", ...],\n",
    "  \"column\": [\"col1\", \"col2\", ...]\n",
    "}\n",
    "\n",
    "<example>\n",
    "SQL:\n",
    "SELECT * from LOGIS_ADMIN.IAWD_TB_DCBSCD_BASISLC_M \n",
    "where basis_lclsf_cd_nm like '%예약구분%'\n",
    "LIMIT 200;\n",
    "\n",
    "{\n",
    "  \"table\": [\"IAWD_TB_DCBSCD_BASISLC_M\"],\n",
    "  \"column\": [\"basis_lclsf_cd_nm\"]\n",
    "}\n",
    "</example>\n",
    "\"\"\"\n",
    "\n",
    "USR_PROMPT_TEMPLATE1=\"\"\"\n",
    "SQL: {sql}\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c230b58-f709-4a7f-a5d9-78c6f7685021",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_aws import ChatBedrock\n",
    "from langchain_core.prompts.chat import ChatPromptTemplate\n",
    "from langchain_core.output_parsers import StrOutputParser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "436d16f5-4d08-4f02-843f-dc487c620384",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_kwargs =  { \n",
    "    \"max_tokens\": 200000,\n",
    "    \"temperature\": 0.0,\n",
    "    \"top_k\": 250,\n",
    "    \"top_p\": 1\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "466e905d-67be-44ec-85e0-0adce0a082a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_kwargs[\"system\"] = SYS_PROMPT_TEMPLATE1\n",
    "model1 = ChatBedrock(model_id=\"anthropic.claude-3-sonnet-20240229-v1:0\", region_name='us-west-2', model_kwargs=model_kwargs)\n",
    "prompt1 = ChatPromptTemplate.from_template(USR_PROMPT_TEMPLATE1)\n",
    "\n",
    "chain1 = prompt1 | model1 | StrOutputParser()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "592db742-3638-4e33-93ea-2a9c31612142",
   "metadata": {},
   "source": [
    "예를 들어 아래 쿼리에 사용된 스키마를 추출해보겠습니다.\n",
    "\n",
    "```SELECT CustomerId, SUM(Total) AS TotalPurchase FROM Invoice GROUP BY CustomerId ORDER BY TotalPurchase DESC LIMIT 5``` "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6e114e6-c10e-48a7-a85d-c073df3d39c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "sql = queries[8].strip()\n",
    "response = chain1.invoke({\"sql\": sql})\n",
    "used_schema = json.loads(response)\n",
    "print(used_schema)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38d2a722-bba8-4043-b627-8b48c0a45cfd",
   "metadata": {},
   "source": [
    "#### 이제 이 쿼리에 사용된 스키마 설명을 조회합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17816589-1b10-4200-844e-6d76f932c244",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_descriptions(table_info, tables, columns):\n",
    "    tables_lower = {table.lower() for table in tables}\n",
    "    columns_lower = {column.lower() for column in columns}\n",
    "    \n",
    "    description = {\n",
    "        \"table\": {},\n",
    "        \"column\": {}\n",
    "    }\n",
    "    \n",
    "    for table_schema in table_info:\n",
    "        for table_name, table_info in table_schema.items():\n",
    "            if table_name.lower() in tables_lower:\n",
    "                description[\"table\"][table_name] = table_info[\"table_desc\"]\n",
    "                for col in table_info[\"cols\"]:\n",
    "                    col_name = col[\"col\"]\n",
    "                    if col_name.lower() in columns_lower:\n",
    "                        description[\"column\"][col_name] = col[\"col_desc\"]\n",
    "    return description"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "052c9d03-949a-45b7-9b0d-3de07601961c",
   "metadata": {},
   "outputs": [],
   "source": [
    "extracted_description = extract_descriptions(schema_description, used_schema['table'], used_schema['column'])\n",
    "print(extracted_description)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c35df41-ac97-4ba0-961e-39e76e611549",
   "metadata": {},
   "source": [
    "#### 이제 쿼리에 대한 자연어 변환을 요청합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9311aae-7d37-46f7-846b-8389369adbd1",
   "metadata": {},
   "outputs": [],
   "source": [
    "SYS_PROMPT_TEMPLATE2 = \"\"\" \n",
    "You are an SQL expert who can understand the intent behind a given SQL query. \n",
    "Translate the SQL query into a natural language request in Korean that a real user might make. \n",
    "\n",
    "- Keep your translation concise and conversational, mimicking how an actual user would ask for the information sought by the query. \n",
    "- Do not reference the <description> section directly and do not use a question form. \n",
    "- Ensure to include all conditions specified in the SQL query in the request.\n",
    "- Write possible business and functional purposes of the query.\n",
    "- Write very detailed purposes and motives of the query in detail.\n",
    "- Skip the preamble and phrase only the natural language request using a concise and straightforward tone without a verb ending. \n",
    "\"\"\"\n",
    "\n",
    "USR_PROMPT_TEMPLATE2=\"\"\"\n",
    "<description>\n",
    "{description}\n",
    "</description>\n",
    "\n",
    "SQL: {sql}\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b733a116-4d58-4543-86fe-d34858c8199f",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_kwargs[\"system\"] = SYS_PROMPT_TEMPLATE2\n",
    "model2 = ChatBedrock(model_id=\"anthropic.claude-3-sonnet-20240229-v1:0\", region_name='us-west-2', model_kwargs=model_kwargs)\n",
    "prompt2 = ChatPromptTemplate.from_template(USR_PROMPT_TEMPLATE2)\n",
    "chain2 = prompt2 | model2 | StrOutputParser()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c28d725d-dcda-4be5-8ffe-130ad299bb7c",
   "metadata": {},
   "source": [
    "#### 자연어 질문을 생성하는 프롬프트는 아래 형식으로 LLM에 전달됩니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3e377fc-8258-4125-9511-900e9056cfa5",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(SYS_PROMPT_TEMPLATE2)\n",
    "print(prompt2.format(description=extracted_description, sql=queries[8]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a598413-330e-43b6-8bc6-7f8cb643436c",
   "metadata": {},
   "outputs": [],
   "source": [
    "response = chain2.invoke({\"sql\": queries[8], \"description\": extracted_description})\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c1a2d45-ecaa-402d-8afd-e0c6ca616d28",
   "metadata": {},
   "source": [
    "#### 다음 쿼리에 대한 자연어 설명은 LLM에 의해 위와 같이 정의되었습니다.\n",
    "\n",
    "```SELECT CustomerId, SUM(Total) AS TotalPurchase FROM Invoice GROUP BY CustomerId ORDER BY TotalPurchase DESC LIMIT 5```\n",
    "\n",
    "#### 아래는 위 과정을 모든 SQL 쿼리에 대해 반복하는 스크립트입니다. (약 1~2분 소요됩니다)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57c7a078-d993-4afd-b460-45a0806dcf11",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "FILE_PATH_1 = './example_queries_temp.jsonl'\n",
    "def query_translation(table_info, queries, chain1, chain2):\n",
    "    if os.path.exists(FILE_PATH_1):\n",
    "        os.remove(FILE_PATH_1)\n",
    "\n",
    "    with open(FILE_PATH_1, 'a') as output_file:\n",
    "        for query in queries:\n",
    "            sql = query.strip()\n",
    "            \n",
    "            try:\n",
    "                response = chain1.invoke({\"sql\": sql})\n",
    "                schema = json.loads(response)\n",
    "            except json.JSONDecodeError:\n",
    "                print(response)\n",
    "                time.sleep(1)  \n",
    "\n",
    "            description = extract_descriptions(table_info, schema[\"table\"], schema[\"column\"])\n",
    "            \n",
    "            input = chain2.invoke({\"sql\": sql, \"description\": description})\n",
    "            # Write input and query to the file in JSON format\n",
    "            data = {\"input\": input, \"query\": sql}\n",
    "            output_file.write(json.dumps(data, ensure_ascii=False) + \"\\n\")\n",
    "            \n",
    "query_translation(schema_description, queries, chain1, chain2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2aaef577-90ef-41e9-89ad-49c4835a2685",
   "metadata": {},
   "source": [
    "#### 쿼리 변환이 완료된 결과는 `./lab3_text2sql_schema_preparation/example_queries_temp.jsonl` 파일에 저장되어 있습니다. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "661cc2ab-3114-444c-bbec-b0f8fcc6fc75",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(FILE_PATH_1, 'r') as file:\n",
    "    for line in file:\n",
    "        data = json.loads(line)\n",
    "        print(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc567324-1948-4c8d-ad41-d48a07473a8a",
   "metadata": {},
   "source": [
    "## Step 3: 샘플 쿼리 벡터 임베딩 및 OpenSearch 저장"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ac40c19-7081-454f-8087-a364b66ee828",
   "metadata": {},
   "source": [
    "이제 <자연어 질문 & SQL 쿼리> 조합의 자연어 질문을 벡터로 임베딩하여, 사용자 질문과 유사한 SQL 쿼리를 찾아내기 용이하도록 저장해야 합니다.\n",
    "\n",
    "아래 구문은 OpenSearch 환경을 초기화합니다. (연결 생성 및 Index 초기화)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b82ea722-2763-4ab1-b2f1-a90e1e7b371e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import yaml\n",
    "from opensearchpy import OpenSearch, RequestsHttpConnection\n",
    "INDEX_NAME = \"example_queries\"\n",
    "\n",
    "def load_opensearch_config():\n",
    "    with open(\"./libs/opensearch.yml\", 'r', encoding='utf-8') as file:\n",
    "        return yaml.safe_load(file)\n",
    "\n",
    "def init_opensearch(config):\n",
    "    mapping = {\"settings\": config['settings'], \"mappings\": config['mappings-schema']}\n",
    "    endpoint = opensearch_domain_endpoint\n",
    "    http_auth = (opensearch_user_id, opensearch_user_password)\n",
    "\n",
    "    os_client = OpenSearch(\n",
    "            hosts=[{'host': endpoint.replace(\"https://\", \"\"),'port': 443}],\n",
    "            http_auth=http_auth, \n",
    "            use_ssl=True,\n",
    "            verify_certs=True,\n",
    "            timeout=300,\n",
    "            connection_class=RequestsHttpConnection\n",
    "    )\n",
    "\n",
    "    create_os_index(os_client, mapping)\n",
    "    return os_client\n",
    "\n",
    "def create_os_index(os_client, mapping):\n",
    "    exists = os_client.indices.exists(INDEX_NAME)\n",
    "\n",
    "    if exists:\n",
    "        os_client.indices.delete(index=INDEX_NAME)\n",
    "        print(\"Existing index has been deleted. Create new one.\")\n",
    "    else:\n",
    "        print(\"Index does not exist, Create one.\")\n",
    "\n",
    "    os_client.indices.create(INDEX_NAME, body=mapping)\n",
    "\n",
    "config = load_opensearch_config()\n",
    "os_client = init_opensearch(config)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7fea2db1-648b-4fd5-9186-9fc8abc6a20e",
   "metadata": {},
   "source": [
    "이제 앞에 만들었던 <자연어 질문 & SQL 쿼리>를 벡터 임베딩으로 변환하고, OpenSearch에 bulk indexing 할 수 있는 Data-Action 포맷으로 구성합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01cd7dd3-ad79-4953-ada5-bcc0e1c46026",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.embeddings import BedrockEmbeddings\n",
    "\n",
    "FILE_PATH_2 = './example_queries.jsonl'\n",
    "emb_model = BedrockEmbeddings(model_id=\"amazon.titan-embed-text-v2:0\", region_name='us-west-2', model_kwargs={\"dimensions\":1024}) \n",
    "\n",
    "def input_embedding(emb_model):\n",
    "    num = 0\n",
    "    if os.path.exists(FILE_PATH_2):\n",
    "        os.remove(FILE_PATH_2)\n",
    "\n",
    "    with open(FILE_PATH_1, 'r') as input_file, open(FILE_PATH_2, 'a') as output_file:\n",
    "        for line in input_file:\n",
    "            data = json.loads(line)\n",
    "            input = data['input']\n",
    "            query = data['query']\n",
    "            \n",
    "            # Data part\n",
    "            body = { \"input\": input, \"query\": query, \"input_v\": emb_model.embed_query(input) }\n",
    "\n",
    "            # Action part\n",
    "            action = { \"index\": { \"_index\": INDEX_NAME, \"_id\": str(num) } }\n",
    "\n",
    "            # Write action and body to the file in correct bulk format\n",
    "            output_file.write(json.dumps(action, ensure_ascii=False) + \"\\n\")\n",
    "            output_file.write(json.dumps(body, ensure_ascii=False) + \"\\n\")\n",
    "\n",
    "            num += 1    \n",
    "\n",
    "input_embedding(emb_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3cda2f81-7c57-4333-a095-3304ad1dabe9",
   "metadata": {},
   "source": [
    "#### 위 코드를 실행한 뒤 `./lab3_text2sql_schema_preparation/example_queries.jsonl` 파일을 열어보면, 변환된 임베딩을 확인할 수 있습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d151126f-16f1-45f5-9b11-ade378977981",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(FILE_PATH_2, 'r') as file:\n",
    "    bulk_data = file.read()\n",
    "        \n",
    "response = os_client.bulk(body=bulk_data)\n",
    "if response[\"errors\"]:\n",
    "    print(\"There were errors during bulk indexing:\")\n",
    "    for item in response[\"items\"]:\n",
    "        if 'index' in item and item['index']['status'] >= 400:\n",
    "            print(f\"Error: {item['index']['error']['reason']}\")\n",
    "else:\n",
    "    print(\"Bulk-inserted all items successfully.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2b51586-09a7-4e02-8cb1-aae1ae0d9f96",
   "metadata": {},
   "source": [
    "#### 이제 OpenSearch에 저장을 완료했습니다."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
